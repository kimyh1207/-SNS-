{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimyh1207/-SNS-/blob/main/Speech_recognition_Wave.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0hOgPd6phMx"
      },
      "source": [
        "# Simple speech recognition\n",
        "\n",
        "Audio 데이터를 다뤄서 학습하는 방법을 배워보도록 합시다.\n",
        "머신러닝 작업과정은 아래와 같습니다.\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process\n",
        "\n",
        "* 모델 완성 후 평가 지표에 따라서 모델을 평가해 봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZglPODWg4J9S"
      },
      "source": [
        "## Project 설명\n",
        "### Task\n",
        "* 1초 길이의 오디오 음성데이터를 이용해 단어를 분류하는 것이 목표입니다.\n",
        "* 주어진 데이터를 이용해 딥러닝 트레이닝 과정을 구현해 보는것이 목표입니다.\n",
        "* This is version 0.01 of the data set containing 64,727 audio files, released on August 3rd 2017.\n",
        "\n",
        "### Baseline\n",
        "* ResNet 구조와 유사한 skip connection 구조를 구현해 보자.\n",
        "* 오버피팅을 방지하기 위한 다양한 방법들을 사용해보자.\n",
        "* Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I3lhvzF4rKF"
      },
      "source": [
        "### Import packages\n",
        "\n",
        "* 우리가 사용할 packages 를 import 하는 부분 입니다.\n",
        "* 필요에 따른 packages를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVi6R2-_phMz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from os.path import isdir, join\n",
        "\n",
        "import random\n",
        "import copy\n",
        "import sys\n",
        "\n",
        "# PyTorch version\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4IeFZj-4_lMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8pXqNOekZf3"
      },
      "source": [
        "### Import modules\n",
        "\n",
        "* Colab 적용을 위한 변수 지정 및 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wARwEZj9p18i"
      },
      "outputs": [],
      "source": [
        "use_colab = True\n",
        "assert use_colab in [True, False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ri_lXEU2h3O"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etgn2vm3phM4"
      },
      "source": [
        "### Load dataset\n",
        "* 사용할 데이터셋을 살펴봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u05iC7S2f8P"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    DATASET_PATH = #TODO\n",
        "else:\n",
        "    DATASET_PATH = \"./\"\n",
        "\n",
        "if not os.path.isdir(DATASET_PATH):\n",
        "    os.makedirs(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBxkj9UsphM5"
      },
      "outputs": [],
      "source": [
        "# npz 파일은 npy 파일들을 압축한 파일입니다.\n",
        "speech_data = np.load(os.path.join(#TODO, \"speech_wav_8000.npz\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naPxNijActj0"
      },
      "source": [
        "* npz 형태의 파일은 npy의 압축형태이며, files 이름 내에 데이터를 저장하고 불러올 수 있습니다.\n",
        "* files를 출력하면, 데이터가 어떤 key값으로 저장되어 있는지 확인할 수 있습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUc0eQoXWFfI"
      },
      "outputs": [],
      "source": [
        "# files를 입력해보시면, 압축된 파일(npy)들의 종류를 확인할 수 있습니다.\n",
        "print(speech_data.files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vufn8u33cz6n"
      },
      "source": [
        "* 각 데이터가 어떤 형태로 저장되어 있는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07X7jASNU2k9"
      },
      "outputs": [],
      "source": [
        "# 불러온 데이터들의 모양\n",
        "print(speech_data[\"wav_vals\"].shape, speech_data[\"label_vals\"].shape)\n",
        "# labels 는 현재 text 상태이기 때문에 추후에 index(int)형태로 바꿔주게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV3CZQzidlr_"
      },
      "source": [
        "* 숫자로 이뤄진 데이터가 진짜 오디오 데이터가 맞는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkLu-SwkYUPW"
      },
      "outputs": [],
      "source": [
        "idx = 219\n",
        "test_audio = speech_data[\"wav_vals\"][idx]\n",
        "test_labels = speech_data[\"label_vals\"][idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKceRI7UXmfv"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "sr = 8000 # 1초동안 재생되는 샘플의 갯수\n",
        "data = test_audio\n",
        "\n",
        "print(test_labels)\n",
        "ipd.Audio(data, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWAbi_w0phM9"
      },
      "source": [
        "### Model dataset setting\n",
        "* 변환된 데이터를 이용해서 학습에 활용할 데이터셋을 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl5pQr-WphM-"
      },
      "outputs": [],
      "source": [
        "sr = 8000 # 음성파일의 sample rate가 8000 인 것을 확인\n",
        "train_wav, test_wav, train_label, test_label = train_test_split(#TODO, # wav 파일들의 데이터\n",
        "                                                                #TODO, # label 파일들의 데이터\n",
        "                                                                test_size=#TODO, # 비율 train, test를 몇퍼센트의 비율로 나눌지\n",
        "                                                                shuffle=#TODO) # 섞을 것인지?\n",
        "                                                                #(파일, 정답) 이 형태로 섞어주게됩니다.\n",
        "\n",
        "# for convolution layers\n",
        "#[40000, 8000] => [40000, 8000, 1] => 40000 * 8000 == 40000 * 8000 * 1\n",
        "# reshape은 항상 데이터의 총량이 변하지 않도록 설정해주시면 됩니다.\n",
        "train_wav = train_wav.reshape([#TODO]) # channel [data len, 8000] -> [data len, 8000, 1]\n",
        "test_wav = test_wav.reshape([#TODO])\n",
        "# (50000, 8000, 1)\n",
        "\n",
        "print(train_wav.shape)\n",
        "print(test_wav.shape)\n",
        "print(train_label.shape)\n",
        "print(test_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsob1V4QY_1-"
      },
      "source": [
        "### Label 데이터를 구분해보자\n",
        "* 현재 정답 데이터는 다양한 단어들이 섞여 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Zu_XcYLZE_7"
      },
      "outputs": [],
      "source": [
        "# 사용되는 모든 라벨을 가져다 set으로 설정 => 중복제거\n",
        "set(speech_data[\"label_vals\"].flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8BVZj5zfWLq"
      },
      "outputs": [],
      "source": [
        "# del raw dataset for mem\n",
        "del speech_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQbpXmA5e9_I"
      },
      "source": [
        "* 총 12개의 클래스르 분류하는 작업이된다.\n",
        "* unknown과 silence에는 target list 이외의 단어가 들어간다. (혹은 노이즈)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVsnK_FaphNC"
      },
      "outputs": [],
      "source": [
        "# target list\n",
        "label_value = ['yes', 'no', 'up', 'down', 'left', 'right', 'on',\n",
        "               'off', 'stop', 'go', 'unknown', 'silence']\n",
        "\n",
        "new_label_value = dict() # 사전에 입력\n",
        "for i, l in enumerate(label_value):\n",
        "    new_label_value[l] = i\n",
        "label_value = new_label_value # 일종의 번역사전을 만들게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4iNBnn_AZxF"
      },
      "outputs": [],
      "source": [
        "label_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3bOhkcnfGyj"
      },
      "source": [
        "* Text 데이터를 index 데이터로 변환\n",
        "    * CIFAR10 데이터셋에서 이미 처리되었던 부분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0aAi4F_phNF"
      },
      "outputs": [],
      "source": [
        "# temp 변수를 이용해서 기존 text 형태인 label을 idx 형태로 변경해준다.\n",
        "temp = []\n",
        "for v in train_label:\n",
        "    temp.append(label_value[v[0]])\n",
        "train_label = np.array(temp)\n",
        "\n",
        "temp = []\n",
        "for v in test_label:\n",
        "    temp.append(label_value[v[0]])\n",
        "test_label = np.array(temp)\n",
        "\n",
        "del temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57Pwj0sLphNI"
      },
      "outputs": [],
      "source": [
        "print('Train_Wav Demension : ' + str(np.shape(train_wav)))\n",
        "print('Train_Label Demension : ' + str(np.shape(train_label)))\n",
        "print('Test_Wav Demension : ' + str(np.shape(test_wav)))\n",
        "print('Test_Label Demension : ' + str(np.shape(test_label)))\n",
        "print('Number Of Labels : ' + str(len(label_value)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0xoCzJi1D-A"
      },
      "source": [
        "### Checkpoint setting\n",
        "* 학습 전반에서 사용할 checkpoint dir을 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbn4AG0F1EG8"
      },
      "outputs": [],
      "source": [
        "# the save point 설정\n",
        "if use_colab:\n",
        "    checkpoint_dir ='./drive/My Drive/train_ckpt/wave/exp1'\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "else:\n",
        "    checkpoint_dir = 'wave/exp1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDB47399bPKf"
      },
      "source": [
        "### Dataset 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50FegMTNphNQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Custom Dataset\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, wav_data, labels, num_classes=12, transform=None):\n",
        "        self.wav_data = #TODO\n",
        "        self.labels = #TODO\n",
        "        self.num_classes = #TODO\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.wav_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wav = self.wav_data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # One-hot encoding\n",
        "        one_hot_label = torch.zeros(#TODO)\n",
        "        one_hot_label[label] = 1\n",
        "\n",
        "        if self.transform:\n",
        "            wav = self.transform(wav)\n",
        "        return wav, one_hot_label\n",
        "\n",
        "# Parameters\n",
        "batch_size = #TODO\n",
        "\n",
        "# For train\n",
        "train_dataset = AudioDataset(#TODO, #TODO, num_classes=#TODO)\n",
        "train_loader = DataLoader(#TODO, batch_size=#TODO, shuffle=True)\n",
        "\n",
        "# For test\n",
        "test_dataset = AudioDataset(#TODO, #TODO, num_classes=#TODO)\n",
        "test_loader = DataLoader(#TODO, batch_size=#TODO, shuffle=False)\n",
        "\n",
        "# Check dataset loaders\n",
        "print(f\"Train dataset batches: {len(train_loader)}\")\n",
        "print(f\"Test dataset batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVlQ7tGRkZwc"
      },
      "source": [
        "### Model 구현\n",
        "* Wave 파일 데이터를 이용해 학습을 할 수 있는 모델을 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imYxkRlyphNT"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Conv1DModel(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes=12):\n",
        "        super(Conv1DModel, self).__init__()\n",
        "        #TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TODO\n",
        "\n",
        "\n",
        "# Example usage\n",
        "sr = 8000\n",
        "input_channels = 1\n",
        "model = Conv1DModel(input_channels=#TODO, num_classes=#TODO).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igiurfQXphNY"
      },
      "outputs": [],
      "source": [
        "criterion = #TODO\n",
        "optimizer = #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_DpuDp3phNb"
      },
      "outputs": [],
      "source": [
        "# 모델을 추론 모드로 설정 (학습 비활성화)\n",
        "model.eval()\n",
        "\n",
        "# 예제 입력 데이터\n",
        "train_wav = torch.randn(1, 1, 8000).to(device)  # 배치 크기=1, 채널=1, 길이=8000\n",
        "\n",
        "# 추론 수행\n",
        "with torch.no_grad():  # 그라디언트 계산 비활성화\n",
        "    predictions = model(train_wav)\n",
        "\n",
        "# 출력 결과 확인\n",
        "print(\"Predictions: \", predictions.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PhoJx8wphNe"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(1, 8000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMMneOo2bIvz"
      },
      "source": [
        "### Model training\n",
        "* 모델 체크포인트로 저장공간을 확인 후 학습을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V_3I0W11MrR"
      },
      "outputs": [],
      "source": [
        "# 체크포인트 저장 함수\n",
        "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_dir='checkpoints', best_loss=None):\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
        "\n",
        "    # 체크포인트 딕셔너리 저장\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss,\n",
        "        'best_loss': best_loss,\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "# 체크포인트 로드 함수\n",
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        print(f\"Checkpoint loaded from {checkpoint_path}\")\n",
        "        return epoch, loss\n",
        "    else:\n",
        "        print(f\"No checkpoint found at {checkpoint_path}\")\n",
        "        return 0, None\n",
        "\n",
        "# 예시: 특정 조건에서 체크포인트 저장\n",
        "best_val_loss = float('inf')  # 초기화\n",
        "current_epoch = 5  # 예제 값\n",
        "current_val_loss = 0.2  # 예제 값\n",
        "\n",
        "if current_val_loss < best_val_loss:\n",
        "    best_val_loss = current_val_loss\n",
        "    save_checkpoint(model, optimizer, current_epoch, current_val_loss, best_loss=best_val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KygmTczhphNg"
      },
      "outputs": [],
      "source": [
        "# 기본 학습 루프\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, max_epochs, checkpoint_dir):\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()  # 학습 모드 활성화\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Training step\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            # GPU가 사용 가능하면 데이터를 GPU로 이동\n",
        "            inputs, labels = #TODO\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = #TODO\n",
        "            loss = #TODO\n",
        "\n",
        "            # Backward pass\n",
        "            #TODO\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{max_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()  # 평가 모드 활성화\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = #TODO\n",
        "                outputs = #TODO\n",
        "                loss = #TODO\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{max_epochs}], Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Checkpoint 저장\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            save_checkpoint(model, optimizer, epoch+1, avg_val_loss, checkpoint_dir=checkpoint_dir)\n",
        "            print(\"Checkpoint saved for better validation loss.\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "# 학습 루프 실행\n",
        "train_model(\n",
        "    model=#TODO,\n",
        "    train_loader=#TODO,\n",
        "    test_loader=#TODO,\n",
        "    criterion=#TODO,\n",
        "    optimizer=#TODO,\n",
        "    max_epochs=#TODO,\n",
        "    checkpoint_dir='checkpoints'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZAf1ldaCkz"
      },
      "source": [
        "### 학습 결과 확인\n",
        "* model fit의 return 값인 history에서 학습에 대한 결과를 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaLXC0aKphNj"
      },
      "outputs": [],
      "source": [
        "# 가중치 로드\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint_epoch_best.pth\")\n",
        "epoch, loss = load_checkpoint(model, optimizer, checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGn-bvDej1Wz"
      },
      "source": [
        "## Evaluation\n",
        "* Test dataset을 이용해서 모델의 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hem0e88_x2yr"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()  # 평가 모드 활성화\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            # GPU가 사용 가능하면 데이터를 GPU로 이동\n",
        "            inputs, labels = #TODO\n",
        "\n",
        "            # 모델 예측\n",
        "            outputs = #TODO\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = #TODO\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # 정확도 계산\n",
        "            if outputs.ndimension() == 2:  # 다중 클래스 분류\n",
        "                _, preds = torch.max(outputs, dim=1)  # 예측 클래스 인덱스\n",
        "                _, true_labels = torch.max(labels, dim=1)  # 실제 클래스 인덱스\n",
        "            else:  # 이진 분류 또는 단일 출력\n",
        "                preds = (outputs > 0.5).long()\n",
        "                true_labels = labels.long()\n",
        "\n",
        "            correct += (preds == true_labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    # 평균 손실 및 정확도 계산\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mbaSZ6vkC_To"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}